# ğŸ“˜ MLLM Research Repository

ë³¸ ë¦¬í¬ì§€í† ë¦¬ëŠ” Multimodal Large Language Models (MLLMs)ì— ëŒ€í•œ í•µì‹¬ ì—°êµ¬ ë…¼ë¬¸, í•™ìŠµ ë°ì´í„°ì…‹, ë²¤ì¹˜ë§ˆí¬ ì •ë³´ë¥¼ ì •ë¦¬í•œ ìë£Œì…ë‹ˆë‹¤. ì—°êµ¬ì, ê°œë°œì, ì‹¤ë¬´ìê°€ ìµœì‹  ë©€í‹°ëª¨ë‹¬ AI ê¸°ìˆ ì„ ë¹ ë¥´ê²Œ ì´í•´í•˜ê³  ì‘ìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“„ Contents

- [1. Key Papers](#1-key-papers)
- [2. Training Datasets](#2-training-datasets)
- [3. Benchmarks](#3-benchmarks)
- [4. Leaderboards](#4-leaderboards)
- [5. Related Open-Source Projects](#5-related-open-source-projects)
- [6. References](#6-references)

---

## 1. Key Papers

| Year | Title | Model | Institution | Link |
|------|-------|-------|-------------|------|
| 2023 | LLaVA: Visual Instruction Tuning | LLaVA | Microsoft, UIUC | [arXiv](https://arxiv.org/abs/2304.08485) |
| 2023 | MiniGPT-4 | MiniGPT-4 | Vision-CAIR | [arXiv](https://arxiv.org/abs/2304.10592) |
| 2024 | mPLUG-Owl2 | mPLUG-Owl2 | DAMO Academy | [arXiv](https://arxiv.org/abs/2308.12966) |
| 2023 | Kosmos-2 | Kosmos | Microsoft | [arXiv](https://arxiv.org/abs/2306.14824) |
| 2024 | Gemini 1.5 | Gemini | Google DeepMind | [blog](https://deepmind.google/technologies/gemini/gemini-15/) |

> âœ… ìµœì‹  ë…¼ë¬¸ì€ `/papers/` ë””ë ‰í† ë¦¬ì— PDFë¡œ ìˆ˜ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

## 2. Training Datasets

| Dataset | Modalities | Size | Source | Link |
|---------|------------|------|--------|------|
| CC3M | Image-Text | 3M pairs | Google | [CC3M](https://github.com/google/cc3m) |
| LAION-5B | Image-Text | 5B pairs | LAION | [LAION](https://laion.ai/blog/laion-5b/) |
| Visual Genome | Image-Text | 108K images | Stanford | [VG](https://visualgenome.org/) |
| ChartQA | Chart-Text | 20K QA pairs | UW | [ChartQA](https://github.com/vis-nlp/ChartQA) |
| ScienceQA | Image+Text+Reasoning | 21K QA | CMU | [ScienceQA](https://github.com/lupantech/ScienceQA) |

---

## 3. Benchmarks

| Benchmark | Description | Task Type | Link |
|-----------|-------------|-----------|------|
| MMMU | Multimodal Math & Science Reasoning | Multi-choice QA | [MMMU](https://mmmu-benchmark.github.io/) |
| MathVista | Math Diagrams + QA | Diagram QA | [MathVista](https://mathvista.github.io/) |
| ChartQA | Chart Image Comprehension | Visual QA | [ChartQA](https://github.com/vis-nlp/ChartQA) |
| ScienceQA | Multimodal Science QA | Multichoice Reasoning | [ScienceQA](https://github.com/lupantech/ScienceQA) |
| MathBench | Text + Diagram + Equation Reasoning | Mixed | [MathBench](https://mathbench.github.io/) |

---

## 4. Leaderboards

- [LLaVA Leaderboard](https://llava-vl.github.io/)
- [MMMU Leaderboard](https://mmmu-benchmark.github.io/)
- [ChartQA Leaderboard](https://chartqa.github.io/)
- [HuggingFace Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open-llm-leaderboard)

---

## 5. Related Open-Source Projects

- [LLaVA](https://github.com/haotian-liu/LLaVA)
- [MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)
- [mPLUG-Owl2](https://github.com/X-PLUG/mPLUG-Owl)
- [OpenFlamingo](https://github.com/mlfoundations/open_flamingo)
- [GPT4-Vision-Adapter](https://github.com/Adapter-Hub/GPT4-Vision-Adapter)

---

## 6. References

- Papers with Code: [https://paperswithcode.com/](https://paperswithcode.com/)
- HuggingFace Model Zoo: [https://huggingface.co/models](https://huggingface.co/models)
- ArXiv MLLM Trackers: [https://www.arxiv-sanity.com/](https://www.arxiv-sanity.com/)

---

ğŸ’¡ *ì´ ì €ì¥ì†ŒëŠ” ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.*
